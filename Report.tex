\documentclass{article}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{scrextend}
\begin{document}
Robotic SLAM 
\textbf{Aswin P Ajayan : 183079032} % Your name

\tableofcontents
\newpage
\section{Introduction}
Terms 

\begin{itemize}
    \item State estimation - find out the pose 
    \item Localisation - pose w.r.to landmark or map
    \item Mapping 
   \item navigation and motion planning - a star, wave front dijkstra 
\end{itemize}

\subsection{What is SLAM}
    Computing robot's poses and the map of the environment at the 
    same time.
\textbf{Localisation} : estimating robots location\\ 
\textbf{Mapping}      : building a MAP\\

\textbf{Given}

\begin{itemize}
    \item Robots control inputs   $$u_{1:T} = \{u_1,u_2,u_3....u_T\}$$
    \item Observations $$z_{1:T} = \{z_1,z_2,z_3,...,z_T\}$$
\end{itemize}

\textbf{Wanted}
\begin{itemize}
    \item Map of the environment $$m$$
    \item path of the Robot $$x_{0:T} = \{x_0,x_1,x_2,...,x_T\}$$
\end{itemize}

Using the robots control inputs we can predict the position of the robot.
From the observations $z_{1:T}$, we can calculate the position of the robot. 
Both the steps have some error associcated with it . Lets call the first
one the model noise and second one the sensor noise. So we have to associate 
a probability with both of them. The error accumulates over time(even if the
error in individual measurements is really small)\\

So in the probalistic terms our problem minimises to 
$$p(x_{0:T},m|z_{1:T},u_{1:T})$$


\includegraphics[width = \linewidth]{graphical_model.png}
\subsection{Full Slam vs online SLAM}
    \begin{itemize}
        \item Full SLAM estimates the entire path $$p(x_{0:T},m|z_{1:T},u_{1:T})$$
        \item Online SLAM estimates only the most recent pose $$p(x_{t},m|z_{1:T},u_{1:T})$$
    \end{itemize}
\includegraphics[width = \linewidth]{online_SLAM.jpg}

\subsection{Types of SLAM}
    occupancy maps created from lidars, sonars etc. - volumetric SLAM
    feature based approach - store features and localise based on that 
    volumetric SLAM maybe  better for navigation applications . 
    Topological representations vs geometric representations.
    Static vs dynamic features.
    Active - robot decides the path so as to build a map vs passive slam -
    may follow a fixed path i.e. path not optimised for mapping/ exploration
\section{Bayes Filter}
\subsection{State Estimation}
    \textbf{Goal} $p(x|z,u)$
    \newline
    \textbf{Recursive Bayes Filter} 

\begin{align*}  
    bel(x_t) & = p(x_t | z_{1:t},u_{1:t})\\
    & = \eta p(z_t|x_t,z_{1:t-1},u_{1:t}) * p(x_t | z_{1:t-1},u{1:t})\\
    & = \eta p(z_t|x_t) * p(x_t | z_{1:t-1},u{1:t})\\
    & = \eta p(z_t|x_t) \int_{x_{t-1}} p(x_t |x_{t-1}, z_{1:t-1},u_{1:t}) * p(x_{t-1}|z_{1:t-1}u_{1:t-1})dx_{t-1}\\
    & = \eta p(z_t|x_t) \int_{x_{t-1}} p(x_t |x_{t-1},u_t) * bel(x_{t-1})dx_{t-1}
 \end{align*}
 we can split this into predict and update steps where\\
 \textbf{Predict Step} 
 $$\overline{bel(x_t)} =  \int_{x_{t-1}} p(x_t |x_{t-1},u_t) * bel(x_{t-1})dx_{t-1}$$
 \textbf{Update Step} 
 $$bel(x_t) =  \eta * p(z_t | x_t) * \overline{bel(x_t)}$$


 \textbf{Bayes filter} gives a framework for recursive state estimation using
 the above equations. The actual realisation  may be kalman filtering , EKF or
 particle filter
 (Linear\ non linear motion models )
 (distributions)
 \textit{Kalman Filter} -  Gaussians , requires linear or linearised model 
 \textit{Particle filter} - Non-parametric , Arbitrary models
 
 \subsection{Probability motion models}
 $p(x_t | u_t,x_{t-1})$ we can model this in two ways 
 \begin{itemize}
     \item odometry models - measurement of velocity (tends to be more accurate)
     \item velocity models - we know the input commands, but no measurement of vel
 \end{itemize}
 \subsection{Model for laser scanners}
 scan z consisits of k beams $z_t \,\epsilon \, \Re^{k}$ i.e. 
 $z_t = \{z_t^1,z_t^2,.....z_t^k\}$,\\ Assuming 
 beams are independednt, then $$p(z_t|x_t,m) = \prod_{i = 1}^{k} p(z_t^i|x_t,m)$$
 \begin{itemize}
     \item Beam endpoint model (likelihood calculated as gaussian blur on occupancy map)
     \item Ray cast model (occlusion, sensor accuray, satuaration , random)
     \item model for range bearing sensors $z_t^i  = (r_t^i,\phi_t^i)^T$
        $$r_t^i = ||m-x|| + gaussian$$
        $$\phi_t^i = \angle (m-x) - \theta + gaussian$$


 \end{itemize}

\section{Kalman filter Equations}
\begin{align*}
    \bar{\mu_t} & = g(u_t,\mu_{t-1})\\
    \bar{\Sigma_t} & = G_t \Sigma_{t-1} G_t^T + R_t\\
    K_t & = \bar{\Sigma_t}H_t^T(H_t\bar{\Sigma_t}H_t^T + Q_t)^{-1}\\
    \mu_t & = \bar{\mu_t} + K_t(z_t - h(\bar{\mu_t}))\\
    \Sigma_t & = (I - K_tH_t)\bar{\Sigma_t}
\end{align*}
\subsection{Summary}
\begin{itemize}
    \item Diverge for large non linearities 
    \item Can deal only single modes 
    \item Successful in medium scale scenes with good data associations
    \item Approximations exists to reduce the computational complexity
\end{itemize}
\textbf{commonly used Datasets:}
\begin{itemize}
    \item Victoria Park Data sets - Trees are the landmark -Data assosciation -girth and height
    \item Tennis Court Dataset - for mapping precescion
\end{itemize}
\section{Extended Kalman Filter vs Unscented Kalman Filter}
\textbf{EKF} works by linearising the state transfer equations 
thus making sure that all the conditional and marginal distributions 
will remain gaussian. Gaussians are closed space. \textbf{UKF} uses
the nonlinear state transmission equation, then tries to sample a 
gaussian distribution from the non-gaussian resulted from the non-linear
operation. 
\subsection{Strategy for chosing sampling points and weights for UKF}
\begin{align*}
X^{[0]} &= \mu\\
X^{[i]} &= \mu + (\sqrt{(n+\lambda)\Sigma})_i  \; for\: i = 1,...,n\\
X^{[i]} &= \mu - (\sqrt{(n+\lambda)\Sigma})_i  \; for\: i = n+1,...,2n\\
w_m^{[0]} &= \frac{\lambda}{n + \lambda}\\
w_c^{[0]} &= w_m^{[0]} + (a -\alpha^2 + \beta)\\
w_m^{[i]} = w_c^{[i]} &= \frac{1}{2(n+\lambda)} \: for \: i = 1,....,2n
\end{align*}
where $\alpha \, \epsilon \, (0,1]$; $k>= 0$ ; $\lambda = \alpha^2(n+k) - n$;\\
too small value of K will lead to UKF ~ EKF . Too large - diverge\\
$\sqrt{\Sigma} =  VD^{1/2}V^{-1}$ , we are sampling the gaussian along the eigen vectors
of the covariance matrix. \\
$$\bar\mu_t = \sum_{1 = 0}^{2n}w^{[i]}g(X^{[i]})$$
$$\bar\Sigma_t = \sum_{1 = 0}^{2n}w^{[i]}(g(X^{[i]}) - \bar\mu_t)(g(X^{[i]}) - \bar\mu_t)^T + R_t$$
\section{Grid Maps}

SLAM problems can make one of the types of maps
\begin{itemize}
    \item \textbf{Feature Based Maps:} Maps is repsented by a few lanndmarks. Advantage of this type of maps is the space time complexity can be smaller compared to Volumetric Maps. On the downside, we have to implement a feature detector - i.e. observations are not directly used in this method. 
        \begin{figure}
            \includegraphics[width = \linewidth]{./feature_maps.jpeg}
            \caption{Feature map overlayed on victoria park}
        \end{figure}

\item \textbf{Volumetric Maps:} Volumetric Maps on the other hand uses all observations and represent the map using a 3D(lidar point cloud) or 2D(range sensor) grid. Occupancy is often shown with a black pixel and free areas are white. Unseen areas are marked with grey. Feature based maps are used in kalman filter implementations, Particle filter based approaches use  Grid mapping and sometimes feature based maps. 
    \begin{figure}%
    \centering
    \subfloat[3D grid map from lidar point cloud]{{\includegraphics[width=0.32\linewidth]{./3dGrid.jpeg} }}%
    \qquad
    \subfloat[Occupancy Grid Map]{{\includegraphics[width=0.6\linewidth]{./gridMap.png} }}%
    \caption{Volumetric Maps}%
    \label{fig:example}%
    \end{figure}
\end{itemize}

\subsection{Representation - Occupancy Grid Map}
 The \textbf{Occupancy grid map} partitions the space into finitely many grid cells. $m = \{m_i\} \ni $ every $m_i$ forms a binary random variable . Size of grid cell is a free parameter which decides the trade of between computational complexity and approximation Error. 
\begin{itemize}
    \item $p(m_i) \to 1 \Rightarrow $ high confidence that grid cell is occupied
    \item $p(m_i) \to 0 \Rightarrow $ high confidence that grid cell is free
    \item $p(m_i) \to 0.5 \Rightarrow $ no information about occupancy of grid cell
\end{itemize}
\textbf{Problem statement:} calculate the posterior $p(m|z_{1:t},x_{1:t})$ \\
\newline
\textbf{Assumptions:}
\begin{itemize}
        \item A grid is either fully occupied or fully free.
        \item Conditional independence of grid cells i.e.  $p(m) = \prod  p(m_i)$
\end{itemize}
\subsection{Algorithm}
Log odds is defined as $$l_o = log\frac{p(m_i)}{1 - p(m_i)}$$ 
$$ p(m_i) = 1 - \frac{1}{1+exp(l_o)}$$
We are hunting for the posterior $p(m_i|z_{1:t},x_{1:t})$. If we express this posterior in odds form , we have 

$$o_{t,i} = \frac{p(m_i|z_{1:t},x{1:t})}{p(\neg m_i | z_{1:t},x{1:t})}$$
$$= \frac{p(m_i|z_t,x_t)}{p(\neg m_i|z_t,x_t)} . \frac{p(m_i| z_{1:t-1},x_{1:t-1})}{p(\neg m_i| z_{1:t-1},x_{1:t-1})} . \frac{p(\neg m_i)}{p(m_i)}$$

In log odds form 
$$l_{t,i} = inverse\_sensor\_model + l_{t-1,i} - l_o$$

In each step we will update only the grids which are in the perception range of the sensor at that particular time instant 

\subsection{Inverse Sensor Model} 
\textbf{inverse\_sensor\_model:} is the implementation of inverse measurement model $p(m_i| z_t,x_t)$ in log odds form.

\subsection{Scan Matching}

"The assumption that poses is known is fundamentally flawed". If we use the pose from raw odometry data the grid map which we recieve is not generally usable. 

"\textbf{Scan-matching} tries to incrementally align two scans or a map to scan without revisiting the past/map. Some common methods used for scan matching - Iterative Closest point match, RANSAC for outlier rejection . A standard cost function is given below 

$${\displaystyle x_t^* = {\underset {x_t}{\operatorname {arg\,max} }}\,\{p(z_t|x_t,m_{t-1})p(x_t | u_{t-1},x_{t-1}^*)\}}$$

\subsection{Summary}
\begin{itemize}
    \item Occupancy Grid maps are used in conjuction with Particle filter based SLAM, feature based maps are used in kalman filter based SLAM.
    \item Occupancy Grid map by itself is not a SLAM algorithm. It assumes known poses. 
    \item Scan matching is used to build usable maps . 
\end{itemize}

\section{Fast SLAM}
\subsection{Review of Particle filters}
\begin{itemize}
        \item Non-parametric recursive Bayes filter
        \item uses samples to represent belief distribution
        \item as opposed to kalman filter family it can model multi modal distributions. 
        \item Uses importance sampling principle to draw samples from arbitrary distributions
            \begin{itemize}
                \item sampling from proposal distribution : 
                    $$x_t^{[j]} \sim \pi(x_t|x_{t-1},u_{t-1})$$
                \item Importance weighting :
                    $$ w_t^{[j]} = \frac{target(x_t^{[j]})}{proposal(x_t^{[j]})} = p(z_t|x_t) $$
                \item Resampling : Draw sample $i$ with probability $w_t^{[j]}$
            \end{itemize}
\end{itemize}
\begin{figure}
    \includegraphics[width = \linewidth]{./importance_sampling.png}
    \caption{Generating samples from arbitrary distribution using importance sampling}
\end{figure}
\subsection{Rao-Blackwellization for SLAM}

SLAM problem is represented as finding the posterior
$$p(x_{1:t},m_{1,x},m_{1,y},\dots{},m_{M,x},m_{M,y})$$
Particle filters are ideal for low dimensional problems . Hence cant be directly used to solve the SLAM problem(dimension 2N + 3). One approach is to estimate the pose using particle filter and then computing map . Mathematically this factorisation can be expressed as 
\begin{align*}
    p(a,b) & = p(b|a).p(a)\\
    \sim p(x_{0:t},m_{1:M}|z_{1:t},u_{1:t}) & =  p(x_{0:t}|z_{1:t},u_{1:t}).p(m_{1:M}|z_{1:t},u_{1:t})\\
    & =  p(x_{0:t}|z_{1:t},u_{1:t}) \Pi p(m_{i}|z_{1:t},u_{1:t})\\
\end{align*}
Effectively we have split it into a path posterior and a map posterior. each particle respresents a path hypothesis and it has an assosicated map with it. Splitting $p(m_{1:M})$ into $\Pi p(m_i)$ reduces the computational complexity further, each of this is calculated by a 2x2 EKF. 
\newline
\newline 
Each particle maintains M 2x2 EKF along with the 3 pose variables 
\begin{figure}
    \includegraphics[width = \linewidth]{./RBPF_particles.png}
    \caption{Particle structure in RBPF-slam}
\end{figure}
\subsection{Algorithm}
\textit{from slides by Prof Syrill Stachniss}\\
\textbf{FastSLAM1.0\_known\_correspondence($z_t,c_t,u_t,X_{t-1}$):}\\
\begin{textit}
    for k = 1 to N do    \hfill      \textcolor{gray}{loop through N particles} \\
    \begin{addmargin}[1em]{2em}
        Let $\langle x_{t-1}^{[k]}, \langle \mu_{1,t-1}^{[k]},\Sigma_{1,t-1}^{[k]} \rangle \dots{} \langle \mu_{M,t-1}^{[k]},\Sigma_{M,t-1}^{[k]} \rangle \rangle$ be a particle in $X_{t-1}$ \\
    
        $x_t^{[k]} \sim p(x_t | x_{t-1},u_{t})$  \hfill \textcolor{gray}{sample pose}\\

        $j = c_t$ \hfill \textcolor{gray}{observed feature with correspondence}\\
        if feature j never seen before:
        \begin{addmargin}[1em]{2em}
            $\mu_{j,t}^{[k]} = h^{-1}(z_t,x_t^{[k]})$ \hfill \textcolor{gray}{initialize mean}\\
            $H = h^{'}(\mu_{j,t}^{[k]},x_t^{[k]})$ \hfill \textcolor{gray}{calculate Jacobian}\\
            $\Sigma_{j,t}^{[k]} = H^{-1}Q_t(H^{-1})^T$ \hfill \textcolor{gray}{initialize covariance}\\
            $w^[k] = p_0$ \hfill \textcolor{gray}{default importance weight}
        \end{addmargin}
        else
        \begin{addmargin}[1em]{2em}
            $\hat z^{[k]} = h(\mu_{j,t-1}^{[k]},x_t^{[k]})$ \hfill  \textcolor{gray}{measurement prediction}\\
            $H = h^{'}(\mu_{j,t-1}^{[k]},x_t^{[k]})$ \hfill \textcolor{gray}{calculate Jacobian}\\
            $Q = H\Sigma_{j,t-1} H^T + Q_t$ \hfill \textcolor{gray}{measurement Covariance} \\
            $K = \Sigma_{j,t-1}^{[k]}H^T Q^{-1}$ \hfill \textcolor{gray}{calculate Kalman gain} \\
            $\mu_{j,t}^{[k]} = \mu_{j,t-1}^{[k]} + K (z_t - \hat z ^{[k]})$  \hfill \textcolor{gray}{update mean} \\
            $\Sigma_{j,t}^{[k]} =(I -KH)\Sigma_{j,t-1}^{[k]}$ \hfill \textcolor{gray}{update covariance}\\
            $w^{[k]} = | 2\pi Q|^{-\frac{1}{2}} exp\{-\frac{1}{2}(z_t - \hat z^{[k]})^T Q^{-1} (z_t - \hat z^{[k]})\}$\\
        \end{addmargin}
        endif\\
        for all unobserved features $j^{'} $ do: \\
           \hspace*{1cm} $\langle \mu_{j,t}^{[k]},\Sigma_{j,t}^{[k]}\rangle =  \langle \mu_{j,t-1}^{[k]},\Sigma_{j,t-1}^{[k]}\rangle$ \hfill \textcolor{gray}{leave unchanged}\\
           end for \\
        $X_t = resample \langle x_{t-1}^{[k]}, \langle \mu_{1,t-1}^{[k]},\Sigma_{1,t-1}^{[k]} \rangle \dots{} ,w^{[k]} \rangle$
    \end{addmargin}

\end{textit}

\section{Implementation in ROS (Particle Filter Localisation)}
Robotic Operating system provides a framework for simulating and testing robotic algorithms and real world interaction. Platform used for simulation 
\begin{itemize}
        \item ROS melodic 
        \item Ubuntu 18.04 (intel i3 3130 with radeon graphics)
        \item ros gazebo for simulating physics
        \item python 2.7
\end{itemize}
Out of the box, ROS still uses python2.7. \\
\subsection{Creating a custom robot}
Various robots available in default in ROS have two major issues. Platform portability, and unneseccary sensors which can bog down the system performance. To avoid this issues, a simple custom robot was made using UDRF - Universal Robot Description Framework. A good tutorial on making a small 2 wheeled robot is available at \href{https://www.theconstructsim.com/ros-projects-exploring-ros-using-2-wheeled-robot-part-1/}{the constructsim website} 
\begin{figure}
    \centering
    \includegraphics[height=30mm]{./custom_robot.png}
\end{figure}
\begin{itemize}
\item \textit{Universal Robot Description Format} provides an easy way to create a custom meshes for a robot. The motion model and sensor model are realised using the gazebo plugins. The robot was created using xacro files: which stands for XML Macros. 
\item sensor: Laser range finder with standard deviation 0.01 and gaussian model was used
\end{itemize}
\subsection{Sensor Model}
Maximum Likelihood field was chosen as the sensor model. Field was precomputed. Field was computed as a convolution between kernel and point landmarks represented a impulses. \\
World was created with cylinders as landmarks. Each cylinder had a radius of 0.2m. So a kernel was created taking into account the shape and the radius

\begin{lstlisting}[language=Python]

def get_kernel(k_size, radius, std):
    """function to generate kernel to produce
    discretised likelihood grid we can convolve
    this kernel with landmarks(ground_truth /
    observed to produce discretised likelihood field)

    :k_size : kernel size (-k_size:k_size) (scaled)
    :radius : radius of landmark
    :std    : standard deviation of meaurement model
    returns: flat top gaussian kernel  """

    cov = np.diag([std ** 2, std ** 2])
    mean = np.array([0, 0], dtype=np.float)
    x_axis = np.arange(-k_size, k_size)
    y_axis = np.arange(-k_size, k_size)
    x_values, y_values = np.meshgrid(x_axis, y_axis)
    grid = np.empty(x_values.shape + (2,))
    grid[:, :, 0] = x_values
    grid[:, :, 1] = y_values
    cov_inv = np.linalg.inv(cov)
    z_norm = np.einsum('...k,kl,...l->...', grid - mean, cov_inv, grid - mean)
    lim = radius ** 2 / (2 * std * std)
    z_norm[z_norm < lim] = 0
    z_norm[z_norm > lim] = z_norm[z_norm > lim] - lim
    kernel = np.exp(-0.5*z_norm)
    kernel = kernel / np.amax(kernel)
    return kernel


\end{lstlisting}
\begin{figure}


     \centering
        \includegraphics[width = \linewidth]{kernel.png}
    \end{figure}   

*einstein summation can speed up the process. Speed is not really much of a concern as kernel calculation is a one time job. \\
Kernel is convolved with point landmark map to get the ML field 
\begin{figure}
\centering
   \includegraphics[width = \linewidth]{./ML field.png}
\end{figure}   

\subsection{Resampling approaches}
    Various Resampling approaches were tried out -
    \begin{itemize}
        \item \textbf{Fitness proportion sampling:} Used the default resampler available in numpy \\
            \textit{numpy.random.choice(particles, num=N, p=weights)}
            \begin{lstlisting}[language=Python]
            indeces = np.random.choice(indeces, NUM, p=weights)
            \end{lstlisting}
        \item \textbf{Roulette wheel selection :} Fitnesss values arranged as CDF around a wheel and a point is chosen at random
        \item \textbf{Stochastic Universal sampling :} Roulette wheel selection will be dominated by a few particles of highest fit. Some particles with high fitness values might be shadowed by the most fit members. This can result is global localisation failure. To avoid this SUS was tried. Though it reduces localisation failure, it can still result in localisation failure  
            \begin{lstlisting}[language=Python]
def lv_sampler(weights):
    """ 
    function to perform low variance sampling 
    taken from S thruns Book
    :weights: importance weights of corresponding particles
    :returns: indeces 
    """
    indeces = []
    NUM = np.float(len(weights))
    r = np.random.uniform(0, 1 / NUM)
    c = weights[0]
    i = 0
    for m in np.arange(NUM):
        u = r + (m - 1) * (1 / NUM)
        while(u > c):
            i += 1
            c += weights[i]
        indeces.append(i)
    return np.array(indeces, dtype='int')


            \end{lstlisting}
    \end{itemize}

    \begin{figure}
        \includegraphics[height = 80mm]{./rl_multi.jpg}
        \caption{Particle structure in RBPF-slam}
    \end{figure}


\subsection{simulation results}
Simulation results obtained where just satisfactory. 
Robot was initialised with some random samples and was able to localise under motion noise and a relatively bad motion model.
\begin{itemize}
        \item \href{https://github.com/aswinpajayan/seminar-related/blob/master/gifs/MCL-final.gif}{Particle localisation}

        \item  \href{https://github.com/aswinpajayan/seminar-related/blob/master/gifs/sensorScans.gif}{Super imposed of ML field}
    \end{itemize}

The main point of concern is that the fittest particle is dominating. This might lead to global localisation failure. A condition in which all the particles corresponds to a single wrong state. This is handled to a certain extend by artificially adding noise to the particles, but better approaches are available in literature
\subsection{suggested improvements}
    \begin{itemize}
        \item Increasing the number of particles. Simualtions are quite heavy and the number of particles was limited by laptop hardware
        \item Better sampling strategy : Current resampling stratgy favours high fit particles to the extent that low fitness particles are often lost. Need a better resampling strategy to improve sampling.
        \item Augmented MCL to counter globalisation failures. Right now globalisation failure is countered by artificially inflating the sensor noise.
        \item Accurate kinematic model for the robot
    \end{itemize}

\subsection{Code Organisation}
    The entire code can be found at github \href{https://github.com/aswinpajayan/localisation-mcl/tree/touchups}{link} in branch touchups
     \begin{itemize}
         \item ROS uses python 2.7. caktin\_make build system is used to build custom messages
         \item robot mesh and model descriptions are present in folder urdf
         \item launch file is used to initialise various ros nodes - present in launch folder (no\_ui\_spawn.launch)
         \item All scripts are found in scripts folder

            \begin{itemize}
                \item scripts/robot\_model.py contains kinematic and sensor models
                    \item scripts/read\_sensor.py contains node to handle hokuyo laser range finder and correspondence algorithm 
                    \item scripts/lv\_resample.py contains various resampling algorithms used
                    \item scripts/my\_MCL.py handles robot localisation
            \end{itemize}
     \end{itemize}
\begin{figure}
        \includegraphics[width = 120mm]{./rosgraph.png}
        \caption{Ros graph generated using rqt\_graph}
    \end{figure}



\section{Future Work}
\begin{itemize}
    \item Perfect Localisation using Augmented MCL and low variance resampling
    \item Move on to implementing RBPF SLAM in ROS 
    \item Running ROS in client server mode offloading heavy computations to lab machine 
\end{itemize}

\section{References and Links}
\begin{itemize}
\item Probabilistic Robotics by Sebastian Thrun
\item \href{https://www.youtube.com/playlist?list=PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN\_}{SLAM Lectures by Prof Cyrill Stachniss}
\item \href{https://www.theconstructsim.com/ros-projects-exploring-ros-using-2-wheeled-robot-part-1/}{URDF tutorials by construct sim}
\item \href{http://wiki.ros.org/ROS/Tutorials}{ROS wiki}
\item Simultaneous Localisation and Mapping (SLAM): Part I The Essential Algorithms By Hugh Durrant-Whyte
\item Webpage from  Prof. Syrill Stachniss can be found \href{http://ais.informatik.uni-freiburg.de/teaching/ws13/mapping/}{here}\\
\item A collection of various robotics algorithms    \href{https://pythonrobotics.readthedocs.io}{pythonrobotics}

\item github repository \url{https://github.com/aswinpajayan/seminar-related.git}
\end{itemize}

\section{Appendix}
\subsection{PF algorithm}


    \begin{figure}
        \centering
        \includegraphics[width=\textwidth]{./PF.png}$^{1}$
    \end{figure}

\subsection{Augmented MCL algorithm}
    \begin{figure}
        \centering
        \includegraphics[height = 80mm]{./Augmented.png}$^{1}$
    \end{figure}




\end{document}

